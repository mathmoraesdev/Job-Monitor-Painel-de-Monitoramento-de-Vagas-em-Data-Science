# ğŸ” Job Monitor â€” Painel de Monitoramento de Vagas em Data Science

Projeto de coleta, categorizaÃ§Ã£o e anÃ¡lise automatizada de vagas de emprego em Data Science, usando Python, Web Scraping, SQL, IA e Power BI.

---

## ğŸ“¸ Dashboard

### VisÃ£o Geral
![VisÃ£o Geral](images/automaÃ§Ã£o_page-0001.jpg)

### AnÃ¡lise de RelevÃ¢ncia
![AnÃ¡lise de RelevÃ¢ncia](images/automaÃ§Ã£o_page-0002.jpg)

### AnÃ¡lise de TendÃªncia
![AnÃ¡lise de TendÃªncia](images/automaÃ§Ã£o_page-0003.jpg)

---

## ğŸš€ Tecnologias utilizadas

| Tecnologia | Uso no projeto |
|---|---|
| Python | OrquestraÃ§Ã£o e anÃ¡lise de dados |
| Requests + BeautifulSoup | Web Scraping de feeds RSS pÃºblicos |
| SQLite + SQL | Armazenamento e modelagem relacional de dados |
| Groq API (LLaMA 3.1) | CategorizaÃ§Ã£o e scoring de vagas com AI Prompting |
| pandas | ManipulaÃ§Ã£o, limpeza e transformaÃ§Ã£o dos dados |
| matplotlib / seaborn | VisualizaÃ§Ãµes e grÃ¡ficos exploratÃ³rios |
| Git / GitHub | Versionamento do projeto |
| Power BI | Dashboard executivo com anÃ¡lise de relevÃ¢ncia |

---

## ğŸ“ Estrutura do projeto

```
job-monitor/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper.py            # Coleta de vagas via RSS (Requests + BeautifulSoup)
â”‚   â”œâ”€â”€ database.py           # Modelagem e operaÃ§Ãµes no banco SQLite
â”‚   â”œâ”€â”€ ai_categorizer.py     # IntegraÃ§Ã£o com Groq API (AI Prompting)
â”‚   â””â”€â”€ pipeline.py           # Orquestrador do fluxo completo
â”œâ”€â”€ images/                   # Screenshots do dashboard
â”œâ”€â”€ data/                     # Banco SQLite gerado apÃ³s execuÃ§Ã£o
â”œâ”€â”€ outputs/                  # CSV exportado para o Power BI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Como rodar

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/mathmoraesdev/Job-Monitor-Painel-de-Monitoramento-de-Vagas-em-Data-Science.git
cd Job-Monitor-Painel-de-Monitoramento-de-Vagas-em-Data-Science
```

### 2. Crie e ative o ambiente virtual
```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

### 4. Configure as variÃ¡veis de ambiente
Crie um arquivo `.env` na raiz do projeto:
```
GROQ_API_KEY=sua_chave_aqui
```
Obtenha sua chave gratuita em: https://console.groq.com

### 5. Execute o pipeline
```bash
cd scripts
python pipeline.py
```

O CSV com as vagas processadas serÃ¡ gerado em `outputs/vagas_processadas.csv`.

---

## ğŸ“Š Fluxo do pipeline

```
RSS Feeds â†’ BeautifulSoup â†’ DataFrame â†’ SQLite â†’ Groq API â†’ CSV â†’ Power BI
```

1. **Scraping** â€” coleta vagas de feeds RSS pÃºblicos (RemoteOK, WeWorkRemotely)
2. **Banco de dados** â€” salva com schema relacional, evitando duplicatas
3. **IA** â€” categoriza cada vaga e atribui score de relevÃ¢ncia via LLaMA 3.1
4. **ExportaÃ§Ã£o** â€” gera CSV para anÃ¡lise no Power BI

---

## ğŸ”’ SeguranÃ§a

O arquivo `.env` estÃ¡ no `.gitignore` e nunca Ã© enviado ao repositÃ³rio. Nunca compartilhe sua chave da API publicamente.

---

**Autor:** Matheus Moraes  
**Contato:** math.moraes.dev@gmail.com  
**LinkedIn:** linkedin.com/in/matheus-moraes-dev-
